{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCpvgG0vwXAZ"
      },
      "source": [
        "# Multilingual Twitter sentiment analysis with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o0LZKJFhE5s"
      },
      "source": [
        "This notebook assumes that the clean dataset is stored on google drive in \"clean\" folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TExQ5Lu53YhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0dee86a-20d2-4708-91cf-57e689d14d6a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviywGyWyKsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb585116-2d13-4cc7-bef0-bdfc598606c5"
      },
      "source": [
        "!pip install tensorflow==1.15.0\n",
        "!pip install bert-tensorflow==1.0.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.33.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 39.2MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=e321e32d1baeddbc269db36b99a3544caa44ef216dd505dc56ebe6d17f7d6d9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting bert-tensorflow==1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow==1.0.1) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZvic2YxnTz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import io\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US_EAnICvP7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87c1b3a-2e82-461a-b2b4-f4d5daa268f0"
      },
      "source": [
        "# Set the output directory for saving model file\n",
        "\n",
        "OUTPUT_DIR = 'output'#@param {type:\"string\"}\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('Model output directory: {}'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model output directory: output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmFYvkylMwXn"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJeJPVq6VtHE"
      },
      "source": [
        "DATA_COLUMN = 'Text'\n",
        "LABEL_COLUMN = 'HandLabels'\n",
        "label_list = ['Positive', 'Negative', 'Neutral']\n",
        "\n",
        "path = '/content/drive/My Drive/clean/'\n",
        "languages = ['Hungarian', 'Portuguese', 'Bosnian',\n",
        "             'Croatian', 'Polish', 'Russian',\n",
        "             'Serbian', 'Slovak', 'Slovenian',\n",
        "             'English', 'German', 'Swedish']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud9WGauWCF1N"
      },
      "source": [
        "def load_dataset(train_langs, test_langs, train_on_test_lang=True):\n",
        "    \n",
        "    # Load train languages\n",
        "    df_train = pd.DataFrame()\n",
        "    for lang in train_langs:\n",
        "        df = pd.read_csv(path + lang + '.csv')\n",
        "        df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "        df.dropna(axis=0, inplace=True)\n",
        "        df_train = pd.concat([df_train, df], ignore_index=True)\n",
        "    \n",
        "    df_train.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    # Load test language\n",
        "    df_test = pd.read_csv(path + test_lang + '.csv')\n",
        "    df_test.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "    df_test.dropna(axis=0, inplace=True)\n",
        "    df_test.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    if train_on_test_lang:\n",
        "        train_size = 0.3\n",
        "        num_train = int(df_test.shape[0] * train_size)\n",
        "        df_train = pd.concat([df_train, df_test.head(num_train)], ignore_index=True)\n",
        "        df_test = df_test.tail(df_test.shape[0]-num_train)\n",
        "    \n",
        "    return df_train, df_test"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhJSe0QHNG7U"
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_multi_cased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "    with tf.Graph().as_default():\n",
        "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "        with tf.Session() as sess:\n",
        "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"], tokenization_info[\"do_lower_case\"]])\n",
        "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccp5trMwRtmr"
      },
      "source": [
        "#Creating a model\n",
        "1. Load BERT\n",
        "2. Create a single new layer for finetunning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o2a5ZIvRcJq"
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB, trainable=True)\n",
        "    bert_inputs = dict(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
        "    bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
        "\n",
        "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "    # Use \"sequence_outputs\" for token-level output.\n",
        "    output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "    # Create our own layer to tune for politeness data.\n",
        "    output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "    output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "    \n",
        "    with tf.variable_scope(\"loss\"):\n",
        "\n",
        "        # Dropout helps prevent overfitting\n",
        "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "        logits = tf.nn.bias_add(logits, output_bias)\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "        # Convert labels into one-hot encoding\n",
        "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "        if is_predicting:\n",
        "            return (predicted_labels, log_probs)\n",
        "\n",
        "        # If we're train/eval, compute loss between predicted and actual label\n",
        "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "        loss = tf.reduce_mean(per_example_loss)\n",
        "        return (loss, predicted_labels, log_probs)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpE0ZIDOCQzE"
      },
      "source": [
        "Next we'll wrap our model function in a `model_fn_builder` function that adapts our model to work for training, evaluation, and prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnH-AnOQ9KKW"
      },
      "source": [
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
        "\n",
        "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "\n",
        "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "\n",
        "        # TRAIN and EVAL\n",
        "        if not is_predicting:\n",
        "\n",
        "            (loss, predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "            # Calculate evaluation metrics.\n",
        "            def metric_fn(label_ids, predicted_labels):\n",
        "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "                #avg_f1 = tf.contrib.metrics.f1_score(label_ids, predicted_labels)\n",
        "\n",
        "                return {\n",
        "                    \"eval_accuracy\": accuracy,\n",
        "                    #\"eva_avg_f1\": avg_f1,\n",
        "                }\n",
        "\n",
        "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "            else:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
        "        else:\n",
        "            (predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "            predictions = {\n",
        "                'probabilities': log_probs,\n",
        "                'labels': predicted_labels\n",
        "            }\n",
        "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "    # Return the actual model function in the closure\n",
        "    return model_fn\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjwJ4bTeWXD8"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 1.0\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 10000\n",
        "SAVE_SUMMARY_STEPS = 10000"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dOeypFcf3LO"
      },
      "source": [
        "def fit_and_evaluate(train, test):\n",
        "    # Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "    train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                       text_a = x[DATA_COLUMN], \n",
        "                                                                       text_b = None, \n",
        "                                                                       label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "    test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                       text_a = x[DATA_COLUMN], \n",
        "                                                                       text_b = None, \n",
        "                                                                       label = x[LABEL_COLUMN]), axis = 1)\n",
        "    \n",
        "    # We'll set sequences to be at most 128 tokens long.\n",
        "    MAX_SEQ_LENGTH = 128\n",
        "    # Convert our train and test features to InputFeatures that BERT understands.\n",
        "    train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "    test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "    \n",
        "    \n",
        "    # Compute # train and warmup steps from batch size\n",
        "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "    \n",
        "    # Specify output directory and number of checkpoint steps to save\n",
        "    run_config = tf.estimator.RunConfig(\n",
        "        model_dir=OUTPUT_DIR,\n",
        "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "    \n",
        "    \n",
        "    model_fn = model_fn_builder(\n",
        "        num_labels=len(label_list),\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        num_train_steps=num_train_steps,\n",
        "        num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "        model_fn=model_fn,\n",
        "        config=run_config,\n",
        "        params={\"batch_size\": BATCH_SIZE})\n",
        "\n",
        "    # Create an input function for training.\n",
        "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "        features=train_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "    \n",
        "    \n",
        "    print(f'Beginning Training!')\n",
        "    current_time = datetime.now()\n",
        "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "    print(\"Training took time \", datetime.now() - current_time)\n",
        "    \n",
        "    \n",
        "    test_input_fn = run_classifier.input_fn_builder(\n",
        "        features=test_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "    \n",
        "    results = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "    print(results)\n",
        "    with open('/content/drive/My Drive/results/results.txt', 'a+') as f:\n",
        "        f.write(\"{}\\n\".format(results))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMx9pWQiVDh-"
      },
      "source": [
        "experiments_same_fam = [\n",
        "    (['English'], 'German'),\n",
        "    (['Serbian'], 'Slovenian'),\n",
        "    (['Serbian'], 'Croatian'),\n",
        "    (['Serbian'], 'Bosnian'),\n",
        "    (['Polish'], 'Slovenian'),\n",
        "    (['Slovak'], 'Slovenian'),\n",
        "    (['Croatian'], 'Slovenian'),\n",
        "    (['Croatian'], 'Serbian'),\n",
        "    (['Croatian'], 'Bosnian'),\n",
        "    (['Slovenian'], 'Croatian'),\n",
        "    (['Slovenian'], 'Serbian'),\n",
        "    (['Slovenian'], 'Bosnian'),\n",
        "]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJJlpXnUTTEB"
      },
      "source": [
        "experiments_diff_lang_fam = [\n",
        "    (['German'], 'Slovenian'),\n",
        "    (['English'], 'Slovenian'),\n",
        "    (['Swedish'], 'Slovenian'),\n",
        "    (['Hungarian'], 'Slovenian'),\n",
        "    (['Portuguese'], 'Slovenian'),\n",
        "]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiuYyFDVTTIY"
      },
      "source": [
        "experiments_large_train_dataset = [\n",
        "    (['Croatian', 'Serbian', 'Bosnian'], 'Slovenian'),\n",
        "    (['English', 'Swedish'], 'German'),\n",
        "]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMkJ2dMSVJZ2"
      },
      "source": [
        "for (train_langs, test_lang) in experiments_same_fam:\n",
        "    with open('/content/drive/My Drive/results/results_mbert.txt', 'a+') as f:\n",
        "        f.write(\"{} {} \\n\".format(train_langs, test_lang))\n",
        "    print(train_langs, test_lang)\n",
        "    df_train, df_test = load_dataset(train_langs, test_lang)\n",
        "    fit_and_evaluate(df_train, df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLXEtIIqG4wz"
      },
      "source": [
        "for (train_langs, test_lang) in experiments_diff_lang_fam:\n",
        "    with open('/content/drive/My Drive/results/results_mbert.txt', 'a+') as f:\n",
        "        f.write(\"{} {} \\n\".format(train_langs, test_lang))\n",
        "    print(train_langs, test_lang)\n",
        "    df_train, df_test = load_dataset(train_langs, test_lang)\n",
        "    fit_and_evaluate(df_train, df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrA0EWI-WGN-"
      },
      "source": [
        "for (train_langs, test_lang) in experiments_large_train_dataset:\n",
        "    with open('/content/drive/My Drive/results/results_mbert.txt', 'a+') as f:\n",
        "        f.write(\"{} {} \\n\".format(train_langs, test_lang))\n",
        "    print(train_langs, test_lang)\n",
        "    df_train, df_test = load_dataset(train_langs, test_lang)\n",
        "    fit_and_evaluate(df_train, df_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}